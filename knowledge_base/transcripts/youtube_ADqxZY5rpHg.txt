(85) Did ChatGPT Just Kill Nano Banana? - YouTube
https://www.youtube.com/watch?v=ADqxZY5rpHg

Transcript:
(00:00) Well, OpenAI couldn't let Google have all the fun. The recent code red led them to dropping two new models in two weeks. With that recent success of Gemini 3, OpenAI needed to release GPT 5.2 to at least remain close to Google. Then with the release of Nano Banana Pro that came a couple days later and kind of took the world by storm, Google >> so hot right now, >> OpenAI needed to answer once again.
(00:27) This time with the new model they dropped today called GPT Image 1.5. Now, I did not get early access to this model. Heck, I wasn't even expecting this model to be released this year, but here we are. We have a fun new treat for us to play with, be excited about for a few weeks, and then inevitably take for granted a few weeks later.
(00:47) I've held off on testing it until this video, but now that we've got it, I'm excited to dig in. But before we demo it, here's what it is. Here's like all the details. The new model is called GPT Image 1.5, and it officially replaces their previous image model. Now, the old one isn't going away entirely, but it's going to be a little more complicated to use.
(01:05) It's still available if you really want it, but now it lives as a custom GPT inside of the GPT section. Moving forward, this new model is going to be the default if you ask OpenAI to generate an image for you. Now, from a performance standpoint, OpenAI says this model can generate images up to four times faster than the previous version.
(01:24) And honestly, faster generation is going to change how often people actually want to use these tools. And if you're a developer, the API costs for both image inputs and outputs are about 20% cheaper compared to the previous GPT image one model. Now, as far as availability goes, this is rolling out today.
(01:42) Right now, as of December 16th, to all ChatGpt users and in the API, so there's no wait list. If you have ChatGpt, free or paid, you should start seeing access to it. Alongside the new model, OpenAI also rolled out a brand new images experience inside of ChatGpt. So, there's this new dedicated images tab in the sidebar, which tells me image generation is no longer just a side thing for OpenAI.
(02:04) It's actually becoming one of its core features. Inside the images tab, you'll see preset visual styles that you can pick from without writing complex prompts. So, things like pop art and sugar cookie and ink work and baseball, bobblehead, fisheye, 3D glam doll, ornament, sketch, plushy, doodle, and a handful more.
(02:25) This is OpenAI very clearly optimizing for normal people who just want a style and want chat GPT to help them come up with it without becoming prompt engineers. The interface also has a cool discovery feature. It suggests trending things people are actually doing. So things like creating holiday cards, turning themselves into famous paintings, or just removing people from the background of photos.
(02:44) So for anyone that doesn't know what to create, it's actually pretty cool to have something like this that just shows off all the ways other people are using it. And one of the more interesting new features is something OpenAI is calling likeness retention. You can do a one-time likeness upload. Basically teaching ChatGpt what you look like and then reuse that appearance across future image generations without needing to re-upload photos every single time.
(03:07) So it kind of seems like a similar idea to the feature previously known as Cameo inside of Sora, but the image version. Now, if you read the news article yourself and didn't see that feature that I just mentioned, you're not alone. OpenAI totally buried it here. Let me show you. If I come to the ChatGpt news article here and scroll all the way down to where it says text rendering, there's one that says markdown rendering.
(03:30) And you can see there's some prompts in here with some details. If we actually read the prompts that it gave inside of this like little news article image that it generated, check this out. In this prompt, this is where this is buried. We've got this section that says a new creation space.
(03:45) This is talking about the dedicated images experience that I just mentioned. But you can see here, this includes preset filters and trending prompts to jump start inspiration, as well as one-time likeness upload, so you can reuse your appearance across future creations without the need to go through your camera roll again.
(04:02) This isn't mentioned anywhere in their main article, but it's mentioned in their like infographic creation prompt here. So yeah, I actually didn't see this feature rolled out in my account yet, but it seems like this could save a ton of time if you generate a lot of images of yourself, you know, for things like YouTube thumbnails, for example.
(04:21) Another small but important quality of life improvement is that you can continue generating new images while others are still processing. So you're no longer locked into waiting for one generation to finish before starting the next one. Again, this sounds pretty minor, but it massively improves how usable this feels. I love that feature.
(04:40) Now, let's talk about what the model actually can do. So, GPT image 1.5 is significantly better at precise editing. It can add elements, remove elements, combine images, blend styles, and transpose objects while preserving lighting, composition, and likeness. OpenAI actually shows a pretty wild example on their blog post where they start with two men and a dog at a party, turn it into a chaotic 2000s party, switch styles like anime and plushy, change outfits, and then eventually remove the men entirely, leaving just the dog
(05:10) streaming solo. And this kind of multi-step editing used to completely fall apart halfway through, but now it continues to remember the context of what you're doing. Instruction following is also supposedly improved. One of the tests that OpenAI highlighted is a 6x6 grid where each cell contains a very specific object placed in an exact row and column.
(05:32) So things like a Greek letter beta, a steaming dumpling, a Canadian goose, all placed correctly. Now, if you ever tried to do something like this with the older image models, you know that this is actually kind of impressive. Text rendering is another big upgrade. This model could handle denser and smaller text than before. OpenAI shows a photorealistic image of a newspaper on a desk that contains an entire markdown article complete with headers, formatting, and accurate numbers.
(05:58) That's a massive improvement for things like mock-ups and marketing assets and UI concepts and product shots. It's also apparently better at creative transformations, meaning it could change the style and context of an image while keeping the sort of essence and like vibe of the original. Like one example they gave takes a photo of two men and turns it into a golden age Hollywood movie poster and it like changes their costumes and lighting and even added specific text credits like directed by Sam Alman.
(06:27) Now a lot of you know that I run a website and newsletter called Future Tools that's all about the latest AI products and announcements. Well, what most people don't know is that Future Tools is built on a single platform called Web Flow. I've been using Web Flow for the past 3 years to design, manage, and scale future tools.
(06:42) And it's grown into this pretty massive directory of AI tools. And now, Web Flow doesn't just build and host sites. It can actually perform an AI audit on your website and tell you how to make it faster, clearer, and more discoverable. I ran an audit on Future Tools, and instantly it started surfacing insights I didn't even realize I needed.
(07:01) Now, I used to work in marketing, so I know all about SEO, but this is different. And honestly, combining the concept of SEO with the power of AI analysis is kind of genius. And once Web Flow discovers all the ways to make your website better, it can actually go and fix everything for you, too.
(07:18) It even highlighted sections that might confuse AI answer engines, which is becoming just as important as traditional SEO. And what I love is that all of this happens visually, so it's really easy to follow along. And if you want to take it even further, the Web Flow marketplace lets you plug in additional AI tools to level up performance, design workflows, content structure, you name it.
(07:37) So, if you want to see how Web Flow can help you build or optimize a site like Future Tools, check out the link in the description. And thank you so much to Web Flow for sponsoring this portion of today's video. Crowds and faces are another area that's quietly improved quite a bit. So GPT image 1.5 is much better at rendering like a whole bunch of small faces in a crowd without things getting weird and like a whole bunch of clones of the same people.
(08:03) On their blog post, OpenAI showed like a photorealistic 1970s London street scene with a focus crowd and a bus advertisement and it actually held up decently. The new model also does a much better job at preserving logos and brand consistency, which is really important if you're a company that uses Jet GPT to make a lot of your brand assets.
(08:24) Now, OpenAI was still very clear in this blog post that this model is not perfect. They do say inaccuracies are still happening. They even showed like a deep sea poster example that's only about 70% correct. So, it's still a creative tool and not necessarily a source of truth. if you haven't make an image for you. Double check the facts in the image.
(08:44) All right, so enough talking about it. I have not tested this model yet. So, let's actually see what this thing can do. Let's get into it. All right, so for my first test, I wanted to test image editing and throw a bunch of edits into one image. So, I uploaded this image here, which if you're a real OG and you've been following me for a long time, you know that this is actually the source image of my old podcast cover.
(09:08) But anyway, I want to edit this image. So, I gave it the prompt, using the uploaded photo of me, remove the person standing on my right while keeping my face, pose, lighting, and background exactly the same. I'm the one with the Padre shirt. I wanted to just make sure it knew which one was me. Then, change my outfit to a black leather jacket and add subtle neon rim lighting behind me.
(09:29) Do not change my facial structure or expression. As a reminder, this was the original image. And well, here's what it created for me. This is the new image. It removed the two people next to me, but we can see it gave me a leather jacket, kept my facial expression the same, added a purple glow, and it even left a person in the background, which if you look at the original image again, this person was sitting here in the background.
(09:53) Removed this person, kept this one. I asked it to remove the person to the right, so I was expecting it to just remove Joe here in the middle, but it actually removed both Joe and Brad here. For a quick comparison to Nano Banana, I gave it the exact same image, the identical prompt, and this is what it generated. So, it changed my pose quite a bit.
(10:11) Even though it was supposed to keep my face, pose, lighting, and background exactly the same. But, I do have a leather jacket. There's a slight purple like reflection. I don't know if this is really a neon purple glow. It's more like a purple light is shining on me from the side. And it did actually keep the background pretty good.
(10:28) It kept both people in the background. I'd have to say this is kind of a draw between the two cuz this one definitely changed up my pose and facial expression and I also think my face looks a lot more AI here, but it did a good job of keeping the background. This one, on the other hand, gave me the purple glow, kept my exact same pose, kept the background for the most part.
(10:46) They both got most of the steps right, but also messed up one or two of the steps. So, pretty even. Chat GPT definitely has less of that AI look to my face, though. So, next up, I want to test like multi-step editing where I give it one image, tell it to change one thing, and then continue to tell it to change one thing with each subsequent prompt.
(11:05) And hopefully, it maintains consistency across all of these prompts. So, I'm starting by feeding it this image of a family at a dinner table and what looks like a 5-year-old who has a glass of wine in front of her, but just ignore that fact. And with my first prompt, I'm telling it to turn the scene into a cozy winter morning with snow visible through the window.
(11:23) Here's our output image. And it looks like it did a pretty good job. We've got the same family with snow out the window. Actually removed the wine glasses in this one. But let's give it a follow-up prompt. Age everyone forward by 15 years while keeping their relationship and positions the same. Another thing I'm noticing before I even hit submit on this prompt is that in this one he was holding like a turkey and in this one he's holding coffee.
(11:46) So it did change some elements throughout the image outside of just the snow. But anyway, let's go ahead and see if it'll age everybody up. 15 years. And here was the result. Um, this girl here does not look any older. Everybody else does look like they aged up. So, let's see. Here's the original image.
(12:01) Notice the girl doesn't change at all, but the mom, the dad, and the son, they definitely seem like they age up a little bit. But apparently this girl, she doesn't age. All right. Now, let's change the style completely. Change the visual style to hand painted oil art. And it looks like it did a pretty good job of using that style.
(12:17) So, we can look through our iterations here, which is nice. We've got our first one where it made the snow. our second one where it aged up three out of the four people. And then our fourth one where it changed it to an oil painting style. Now, let's have it replace the kitchen with a mountain cabin interior.
(12:31) Let's see what it changes with that. So, now we've got our kitchen replaced with a mountain cabin here. Let's do one last edit and tell it to remove everyone except one person and place that person alone at the table, still in the same lighting and camera angle. And here's our final image. One man sitting at the cabin table by himself.
(12:50) All right, so let's see how well it followed through with the consistency. This was the original image I gave it. Here's the image where it added snow in the background. A few little things changed like what he's holding and some of the shelves and things are in different spots. Then we aged everybody up 15 years, which it did decently except not the girl.
(13:08) Then we changed it to an oil painting. Then we changed it to a cabin. And then we finally removed everybody else and just left one man at the cabin. So that was the chain of events that got us to this image. and it did a pretty decent job of maintaining consistency and not getting too off the rails. But of course, I wanted to test the exact same identical prompts in Nano Banana.
(13:26) So, same initial image, same initial prompt. Here's the image where it added snow in the scene. It seemed to have removed less things from the image than what ChatGpt did. And I feel like it really maintained consistency a lot better than chat GPT. It kind of only changed the snow in the background. When I went to age everybody up by 15 years, it kind of did the same thing as the other one.
(13:51) It aged the mom, the dad, the son, and even the dog got gray hair, but the girl still looks roughly the same age. Maybe a little bit older, but definitely not 15 years older. Here's the girl in the original one. Here's the dog in the original one. We can see it definitely aged up the girl here, but you know, if it added 15 years, you'd think she'd be roughly 20.
(14:07) I'm not seeing a 20-year-old here. Change the visual style to an oil painting. Eh, kind of. It almost just looks like it threw like an oil painting filter over a real image as opposed to like making an oil painting. Replace the kitchen with a cabin interior. Did that. And then finally remove everybody but one person.
(14:24) It left the mom here. The room went back from being a cabin to being a kitchen. So it sort of lost the plot a little bit. It's no longer a cabin. It's no longer an oil painting. It almost took the original image and removed everybody from that image, leaving just the mom. but it sort of lost all of the other prompts that we did to get there.
(14:43) So, chat GPT definitely does a better job of remembering the previous prompts and remembering the previous steps that got us to this image, but Nano Banana definitely seems to maintain consistency a little bit better where it's not actually changing a lot of things in the image other than what you ask it for. So, once again, they both have pros and cons.
(15:05) I still think nano banana might be a little bit better, but chat GPT seems to have better memory of like the context of each next image in line. That makes sense. Next up, I wanted to test the spatial reasoning and kind of recreate the little grid test they did in their blog post. So, I said create a white canvas divided into nine uneven rectangles like a magazine layout.
(15:26) And then I told it what to put in each box. This was what it gave me. And well 1 2 3 4 5 6 7 8 9 10. It made 10 boxes instead of nine like I asked it to. So that's one sort of strike against it. But let's see how well it maintained the rest of it. So nine uneven rectangles. It made 10 uneven rectangles.
(15:46) Top left, steaming cup of coffee. Top right, a folded city map. This appears to be an unfolded city map, but okay. Center left, a pair of headphones. Cool. Center right, a glowing light bulb. Bottom center, a red notebook. Each object must stay fully inside its rectangle and not overlap any borders. Well, I don't know about that.
(16:04) Our red notebook's going over the border a little bit. So, pretty decent, but it definitely missed a few instructions. Comparing this to Gemini, again, identical prompt. And here's what it generated. 1 2 3 4 5 6 7 8 9 10. So, for whatever reason, it also generated 10 squares instead of nine. But looking at our prompt here, top left, steaming cup of coffee. Top right, folded city map.
(16:26) Center left, pair of headphones. Yeah, I mean that could have, I guess, gone here as well. Center right, a glowing light bulb. Yep. Bottom center, a red notebook. Yep. And it kept everything within the lines. I mean, another tie. I mean, they're both about as good as each other.
(16:44) They both screwed up and put 10 boxes instead of nine. And I actually feel like Nano Banana followed the instructions slightly better. We got a folded map. It stayed within the lines. It took the magazine layout portion of it literally and made it look like a magazine. I got to give the edge to Nano Banana on this one. >> Top five most exciting bananas in the world.
(17:02) >> So, for the next one, I wanted to test text, especially like small text in an image. So, I gave it the prompt, create a photorealistic image of a laptop on a desk with a browser window open. On the screen display a product pricing page that includes a large bold title, a small footnote with an asterisk, a comparison table with at least three rows, fine print legal text at the bottom.
(17:24) All text must be readable, properly aligned, and correctly spelled. And here's what we got from that. We've got our pricing page. We've got our small disclaimer. We've got our three columns. We've got all of our text is legible and readable. I'm not actually seeing any errors in the text. Let's see the disclaimer. Prices are in USD. Additional terms and conditions apply.
(17:41) Cancel anytime. For full details, please review our terms of service and privacy policy. Honestly, Chat GPT nailed this one. Let's compare to what Nano Banana does. Identical prompt once again. Here's what it gave us. Pretty good. Ultimate software sweet pricing. Prices are build annually. Monthly options available.
(18:00) It's a little fuzzy, but it's readable. We do have a disclaimer down here. It's a little too blurry for my eyes to make out, but I think it's actual words. ChatGpt definitely did it better. We can see that the text is sort of kind of getting blurry and not high enough resolution. Let me download the full size to compare. All right. So, when I download the full size image off of Nanobanana, not the preview on the website, we can actually see it did a fairly decent job.
(18:26) We can see up in the URL bar product.pricing.com, but the text is still a little sort of garbled, right? It looks like upscaled text. So, it was like pixelated text that they upscaled. And this is kind of what that tends to look like. But you can actually make out what it says and it does sort of make sense. So, Ultimate Software Inc., all rights reserved.
(18:44) Terms of service and privacy policies apply. Prices subject to change without notice. Taxes not included. I mean, it did a good job. So, yeah, they both did a pretty good job. I think the chat GPT text is a little bit more readable, a little more legible than the other one, but I can't complain with either of those images.
(19:01) So, I wanted to test this like cross era identity thing. So, I uploaded this silly image of myself and I said, "Transform the uploaded photo of a person into three sideby-side portraits." Version one, Renaissance oil painting. Version two, 1980s studio portrait photography. Version three, modern cinematic film still. Keep the same facial structure, head angle, and expression across all three.
(19:21) And this is what it generated. This is our Renaissance painting. This is our 80s photo studio. And this is our cinematic. I mean, yeah, it did a pretty good job comparing this to Nano Banana with the identical image and prompt. And this is interesting. It gave us three photos. Renaissance88s cinematic, but it sort of stylized them and overlapped them.
(19:40) So if you were going to try to like cut out each image and use them separately, well, you couldn't really do it with this version. So chat GPT, yeah, I'd give this one to Chad GPT. Now, they did mention that you should be able to generate tons and tons of people in an image without them getting wonky.
(19:56) So I gave it the prompt, generate a photorealistic outdoor music festival scene at sunset. include a dense crowd where some people are cheering, some are filming with phones, and some are talking to each other. Faces should be proportionate and expressive with no distortions or repeated faces. And here's what we got out of that.
(20:11) Now, none of them are looking at the camera, so it's hard to say whether or not we got repeated faces, but it does look like a bunch of different individuals, some cheering, some with phones. Now, comparing this to Gemini, exact same prompt. Here's what Gemini created. And I actually think the Gemini version looks more realistic.
(20:28) This looks like a photo taken at a concert where the Ched PT one, I don't know, it's got some AI uncanniness to it. So, definitely got to give this one to Nano Banana. And then finally, I wanted to test how this would work with like a brand and keeping logos consistent cuz that was one thing they did mention this new model would do.
(20:48) So, create a minimalist brand system for a fictional coffee company called Ember. Generate three images: a storefront sign, a takeaway cup, and a bag of coffee beans. used the same logo, color palette, and typography across all three images without variation. And it created one image with all three of those.
(21:03) We've got our storefront sign, our takeaway cup, and our coffee bag. And all the logos look identical. Branding and colors all the same. I think it did a good job on this one. Gemini, once again, exact same prompt, and it actually generated it as three separate images, interestingly. So, we have our I guess this is the storefront sign.
(21:21) It's just not on a storefront. Here's our takeaway coffee cup. If we look at the logo, it looks to be the same logo. And here's our bag of coffee beans and also the same logo. I would give this a tie between the two. I'd say they both do equally as good of a job at this. I kind of like that Gemini split it out for me.
(21:37) All right, so that's what I got for you today. We got a brand new image model out of ChatGpt and OpenAI, and it's pretty good. If I had to say which one was better between Nano Banana and ChatGpt, I think I'm still slightly more impressed with Nano Banana, but ChatGpt is catching up. I do feel like Nano Banana when you're editing images, it will do a better job at sort of keeping the things you want in the images where ChatGpt still seems to change a lot of stuff even though you might only be asking for one little change. But
(22:06) overall, they're pretty good. And as we like to say in this space, this is the worst it's ever going to be. And I just love getting new AI models that we can play with. And we got one right before the holidays. So, all of us should have some decent downtime to jump in and play with some new toys.
(22:21) And we got a new toy today, which is always great. So, if you like videos like this and you love nerding out about AI, you want to stay looped in on the latest news, the latest tools, as well as learn how to use them, give this video a thumbs up and subscribe to this channel, and I will make sure more stuff like this shows up in your YouTube feed and that you always stay looped in on the latest advancements in the world of AI.
(22:42) That's what I do. That's what I keep up with on a daily basis and then turn around and try to share it with you. So, again, if you like that stuff, consider subscribing to this channel. Thank you so much for hanging out with me and hopefully I'll see you in the next one. Peace out. Thank you so much for nerding out with me today.
(22:55) If you like videos like this, make sure to give it a thumbs up and subscribe to this channel. I'll make sure more videos like this show up in your YouTube feed. And if you haven't already, check out futuretools.io where I share all the coolest AI tools and all the latest AI news. And there's an awesome free newsletter. Thanks again.
(23:11) Really appreciate you. See you in the next one.
