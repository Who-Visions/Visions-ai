{
    "title": "Scaling Compute: Agentic Code Reviews with Claude Code & MCP",
    "summary": "This workflow demonstrates how to transform a single CLI prompt into a complex agentic chain using Claude Code and Model Context Protocol (MCP). By defining a custom slash command, the user triggers a multi-step process that captures local git context, distributes analysis across three distinct LLM providers (OpenAI, Anthropic, Gemini) in parallel, and synthesizes the results into a unified, prioritized security and code quality report.",
    "steps": [
        {
            "time": "01:00",
            "action": "Execute custom slash command `/project:jpompt_ultra_diff_review`",
            "tool": "Claude Code CLI",
            "reasoning": "Triggers a pre-defined prompt template stored in `.claud/commands`, initiating a multi-step agentic workflow from a single user input."
        },
        {
            "time": "01:12",
            "action": "Generate context file `diff.md` and append `git diff` output",
            "tool": "Bash / File System",
            "reasoning": "Automates context gathering by extracting the current code changes directly from the local environment to prepare for LLM analysis."
        },
        {
            "time": "01:28",
            "action": "Execute MCP tool `just-prompt:prompt_from_file_to_file` targeting 3 models",
            "tool": "MCP Server (just-prompt)",
            "reasoning": "Scales compute by running the 'Big 3' providers (OpenAI o3-mini, Claude 3.7, Gemini 2.0) in parallel to gain diverse perspectives and reduce model-specific bias."
        },
        {
            "time": "02:07",
            "action": "Read output files generated by the parallel model runs",
            "tool": "Claude Code (File Read)",
            "reasoning": "The agent retrieves the asynchronous results from the file system to bring the external model insights back into its active context window."
        },
        {
            "time": "02:18",
            "action": "Synthesize analysis into `fusion_ultra_diff_review.md`",
            "tool": "Claude Code (LLM Synthesis)",
            "reasoning": "Acts as an 'Evaluator' agent, merging the three separate analyses into a single coherent document to identify consensus on critical issues."
        },
        {
            "time": "02:43",
            "action": "Present prioritized recommendations (Critical, Medium, Low)",
            "tool": "Claude Code (UI)",
            "reasoning": "Delivers actionable intelligence to the human-in-the-loop, highlighting specific security vulnerabilities (e.g., hardcoded API keys) found by the swarm."
        }
    ],
    "key_takeaways": [
        "Scaling compute scales impact: Using multiple models in parallel provides deeper, more reliable code analysis than a single model.",
        "Prompt Templates as Software: Custom slash commands allow engineers to version-control complex agentic workflows as simple Markdown files.",
        "The 'Evaluator' Pattern: A critical step in agentic workflows is synthesizing parallel outputs to filter noise and highlight consensus.",
        "MCP as the Bridge: Model Context Protocol servers enable the CLI agent to orchestrate external tools and other LLM providers seamlessly."
    ]
}